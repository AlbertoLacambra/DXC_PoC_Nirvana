# Estrategia Single-AKS

## Resumen Ejecutivo

La **Single-AKS Strategy** es una decisi√≥n arquitectural clave del proyecto CloudMind que maximiza el aprovechamiento de infraestructura existente mediante **aislamiento por namespaces** en lugar de crear nuevos clusters AKS.

## Contexto de la Decisi√≥n

### Situaci√≥n Inicial

**Infraestructura Existente**:
- AKS Cluster: `dify-aks` (Kubernetes 1.30.14)
- Namespace: `dify` (plataforma AI en producci√≥n)
- Recursos compartidos: PostgreSQL, Storage, Key Vault, VNet
- Coste mensual: ~‚Ç¨222/mes

**Opciones Evaluadas**:

| Opci√≥n | Descripci√≥n | Coste | Ventajas | Desventajas |
|--------|-------------|-------|----------|-------------|
| **A: Multi-AKS** | 2 nuevos clusters (hub + spoke) | +‚Ç¨455/mes | Aislamiento total | Coste elevado, complejidad |
| **B: Single-AKS** | Namespaces en cluster existente | +‚Ç¨5/mes | M√≠nimo coste | Dependencia compartida |
| **C: Hybrid** | 1 nuevo cluster + namespace | +‚Ç¨205/mes | Balance | Coste moderado |

**Decisi√≥n**: Opci√≥n B - **Single-AKS Strategy** ‚úÖ

## Implementaci√≥n

### Arquitectura de Namespaces

```mermaid
graph TB
    subgraph AKS["AKS Cluster: dify-aks"]
        subgraph NS1["Namespace: dify"]
            D1[Dify API]
            D2[Dify Worker]
            D3[Dify Web]
            D4[RAG Services]
        end
        
        subgraph NS2["Namespace: cloudmind"]
            C1[Control Center UI]
            C2[API Gateway]
            C3[PoC Services]
        end
        
        subgraph NS3["Namespace: use-cases (Future)"]
            U1[FinOps Agents]
            U2[Governance Bots]
            U3[Incident Response]
        end
        
        subgraph Resources["Cluster Resources"]
            CPU[CPU Pool]
            Memory[Memory Pool]
            Storage[Storage Classes]
            Network[Network Policies]
        end
    end
    
    NS1 --> CPU
    NS2 --> CPU
    NS3 --> CPU
    NS1 --> Memory
    NS2 --> Memory
    NS3 --> Memory
    
    style NS2 fill:#e1f5ff
    style NS3 fill:#f0f0f0
```

### Resource Quotas

**Configuraci√≥n Implementada**:

```yaml
# Namespace: dify (existing)
apiVersion: v1
kind: ResourceQuota
metadata:
  name: dify-quota
  namespace: dify
spec:
  hard:
    requests.cpu: "8"
    requests.memory: 16Gi
    limits.cpu: "12"
    limits.memory: 24Gi
    pods: "50"
    services: "20"
    persistentvolumeclaims: "10"

# Namespace: cloudmind (NEW)
apiVersion: v1
kind: ResourceQuota
metadata:
  name: cloudmind-quota
  namespace: cloudmind
spec:
  hard:
    requests.cpu: "4"
    requests.memory: 8Gi
    limits.cpu: "6"
    limits.memory: 12Gi
    pods: "30"
    services: "15"
    persistentvolumeclaims: "5"
```

**Distribuci√≥n de Recursos**:

```
Cluster Total Capacity: ~16 CPU / 32Gi Memory

Allocation:
‚îú‚îÄ‚îÄ dify namespace: 8 CPU / 16Gi (50%)
‚îú‚îÄ‚îÄ cloudmind namespace: 4 CPU / 8Gi (25%)
‚îú‚îÄ‚îÄ system pods: 2 CPU / 4Gi (12.5%)
‚îî‚îÄ‚îÄ buffer: 2 CPU / 4Gi (12.5%)
```

### Network Policies

**Aislamiento de Red**:

```yaml
# cloudmind namespace - allow ingress from specific sources
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: cloudmind-ingress
  namespace: cloudmind
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: dify
    - podSelector: {}
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: dify
    - podSelector: {}
  - to:  # Allow external services
    - namespaceSelector: {}
```

**Principios**:
- ‚úÖ Default deny all traffic
- ‚úÖ Allow inter-namespace communication controlada
- ‚úÖ Allow egress to servicios externos (PostgreSQL, Storage)
- ‚úÖ Deny traffic no autorizado

## Ventajas de la Estrategia

### üí∞ Ahorro de Costes

**Comparativa Real**:

| Recurso | Multi-AKS | Single-AKS | Ahorro Mensual |
|---------|-----------|------------|----------------|
| Hub AKS Cluster | ‚Ç¨200 | ‚Ç¨0 | ‚Ç¨200 |
| Spoke AKS Cluster | ‚Ç¨200 | ‚Ç¨0 | ‚Ç¨200 |
| Container Insights (2 clusters) | ‚Ç¨50 | ‚Ç¨0 | ‚Ç¨50 |
| ACR Basic | ‚Ç¨5 | ‚Ç¨5 | ‚Ç¨0 |
| **TOTAL** | **‚Ç¨455** | **‚Ç¨5** | **‚Ç¨450/mes** |

**ROI**:
- Ahorro anual: **‚Ç¨5,400**
- Ahorro 2 a√±os: **‚Ç¨10,800**
- Tiempo de implementaci√≥n reducido: **70% m√°s r√°pido**

### üöÄ Simplicidad Operacional

**Operaciones Reducidas**:
- ‚úÖ 1 cluster que actualizar (vs 3)
- ‚úÖ 1 Container Insights que monitorizar
- ‚úÖ 1 RBAC configuration que mantener
- ‚úÖ 1 networking setup que gestionar

**Time to Market**:
```
Multi-AKS:
‚îú‚îÄ‚îÄ Deploy Hub AKS: 20 mins
‚îú‚îÄ‚îÄ Deploy Spoke AKS: 20 mins
‚îú‚îÄ‚îÄ Configure peering: 10 mins
‚îú‚îÄ‚îÄ Setup monitoring: 15 mins
‚îî‚îÄ‚îÄ TOTAL: ~65 mins

Single-AKS:
‚îú‚îÄ‚îÄ Create namespace: 2 mins
‚îú‚îÄ‚îÄ Apply resource quotas: 1 min
‚îú‚îÄ‚îÄ Configure ACR pull: 3 mins
‚îî‚îÄ‚îÄ TOTAL: ~6 mins
```

**Reducci√≥n**: **90% tiempo de deployment**

### üîÑ Shared Resources

**Servicios Compartidos**:

```mermaid
graph LR
    NS_Dify[Namespace: dify] --> PG[(PostgreSQL)]
    NS_Cloud[Namespace: cloudmind] --> PG
    
    NS_Dify --> SA[(Storage Account)]
    NS_Cloud --> SA
    
    NS_Dify --> KV[Key Vault]
    NS_Cloud --> KV
    
    NS_Dify --> CI[Container Insights]
    NS_Cloud --> CI
    
    style CI fill:#c8e6c9
    style PG fill:#c8e6c9
    style SA fill:#c8e6c9
    style KV fill:#c8e6c9
```

**Beneficios**:
- Free tier Container Insights compartido
- PostgreSQL connection pool optimizado
- Storage Account sin duplicaci√≥n
- Key Vault single source of truth

## Trade-offs y Mitigaciones

### ‚ö†Ô∏è Riesgos Identificados

| Riesgo | Probabilidad | Impacto | Mitigaci√≥n |
|--------|--------------|---------|------------|
| **Noisy neighbor** | Media | Medio | Resource quotas estrictos + monitoring |
| **Cluster failure** | Baja | Alto | Backup strategy + disaster recovery plan |
| **Resource contention** | Media | Bajo | Over-provisioning del cluster + autoscaling |
| **Security isolation** | Baja | Alto | Network policies + RBAC strict |

### ‚úÖ Mitigaciones Implementadas

**1. Resource Quotas Estrictos**:
```yaml
# Garantiza que ning√∫n namespace puede consumir >50% recursos
hard:
  limits.cpu: "6"      # Max 6 CPU por namespace
  limits.memory: 12Gi  # Max 12Gi por namespace
```

**2. Monitoring y Alertas**:
```yaml
# Container Insights alerts configurados
- CPU usage > 80% por namespace (5 mins)
- Memory usage > 85% por namespace (5 mins)
- Pod evictions en cualquier namespace
- Node pressure events
```

**3. Network Policies**:
```yaml
# Aislamiento por defecto
policyTypes:
  - Ingress  # Control de tr√°fico entrante
  - Egress   # Control de tr√°fico saliente
```

**4. RBAC Segregation**:
```yaml
# Usuarios dify: solo acceso a namespace dify
# Usuarios cloudmind: solo acceso a namespace cloudmind
# Admins: acceso completo
```

## Escalabilidad Futura

### üìà Plan de Crecimiento

**Phase 0 (Actual)**: 1 namespace adicional
```
Cluster capacity: 16 CPU / 32Gi
‚îú‚îÄ‚îÄ dify: 8 CPU / 16Gi (50%)
‚îú‚îÄ‚îÄ cloudmind: 4 CPU / 8Gi (25%)
‚îî‚îÄ‚îÄ Available: 4 CPU / 8Gi (25%)
```

**Phase 1**: 2-3 namespaces adicionales
```
Cluster capacity: 16 CPU / 32Gi (same)
‚îú‚îÄ‚îÄ dify: 8 CPU / 16Gi (50%)
‚îú‚îÄ‚îÄ cloudmind: 3 CPU / 6Gi (19%)
‚îú‚îÄ‚îÄ use-case-1: 2 CPU / 4Gi (12%)
‚îú‚îÄ‚îÄ use-case-2: 2 CPU / 4Gi (12%)
‚îî‚îÄ‚îÄ Available: 1 CPU / 2Gi (6%)
```

**Phase 2**: Scale-out si necesario
```
Trigger: >85% cluster utilization durante 7 d√≠as
Action: Deploy nuevo AKS cluster
Cost impact: +‚Ç¨200/mes
Strategy: Migrate low-priority workloads
```

### üîÑ Migration Path

**Si se requiere Multi-AKS en el futuro**:

```bash
# Step 1: Deploy nuevo AKS cluster
terraform apply -target=module.spoke_aks

# Step 2: Configure peering
terraform apply -target=module.vnet_peering

# Step 3: Migrate workloads gradualmente
kubectl get all -n cloudmind -o yaml > backup.yaml
# Apply to new cluster
kubectl apply -f backup.yaml --context=new-cluster

# Step 4: Update DNS/routing
# Step 5: Decommission old namespace
```

**Tiempo estimado**: 2-3 horas
**Downtime**: <5 minutos con blue/green deployment

## Monitorizaci√≥n

### üìä M√©tricas Clave

**Dashboard Container Insights**:

```yaml
Cluster Health:
  - Node CPU usage: <70%
  - Node Memory usage: <75%
  - Node disk pressure: 0 events
  - Pod eviction rate: <1/hour

Namespace: dify
  - CPU usage: 4-6 CPU (50-75% quota)
  - Memory usage: 10-12Gi (62-75% quota)
  - Pod count: 15-25 (30-50% quota)
  - Restart rate: <2/hour

Namespace: cloudmind
  - CPU usage: 1-2 CPU (25-50% quota)
  - Memory usage: 3-5Gi (37-62% quota)
  - Pod count: 5-10 (16-33% quota)
  - Restart rate: <1/hour
```

**Alertas Configuradas**:
- üî¥ Critical: Namespace CPU >90% quota (5 mins)
- üü† Warning: Namespace Memory >85% quota (10 mins)
- üü° Info: Cluster node count changed
- üîµ Debug: New pod deployment

## Conclusiones

### ‚úÖ Decisi√≥n Validada

**Resultados Reales (Enero 2025)**:
- ‚úÖ Coste real: ‚Ç¨5/mes (vs ‚Ç¨455/mes estimado Multi-AKS)
- ‚úÖ Deployment time: 6 mins (vs 65 mins Multi-AKS)
- ‚úÖ Zero downtime en Dify durante implementaci√≥n
- ‚úÖ Resource isolation efectivo con quotas
- ‚úÖ Monitoring consolidado en Container Insights

**Recomendaci√≥n**: Mantener Single-AKS Strategy hasta Phase 2 (>85% utilization)

## Referencias

- [Arquitectura Overview](overview.md)
- [Recursos Desplegados](deployed-resources.md)
- [An√°lisis de Costes](../costs/analysis.md)
- [Kubernetes Best Practices](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/)
